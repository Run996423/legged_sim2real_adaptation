<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8"/>
    <title>Real-Time Dynamic Parameter Estimation for Legged Robot Sim-to-Real Adaptation</title>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <style>
        :root {
            --bg: #f9fafb;
            --fg: #111827;
            --muted: #4b5563;
            --accent: #2563eb;
            --accent-soft: #dbeafe;
            --border: #e5e7eb;
            --card-bg: #ffffff;
        }

        * {
            box-sizing: border-box;
        }

        body {
            margin: 0;
            font-family: system-ui, -apple-system, BlinkMacSystemFont,
            "Segoe UI", sans-serif;
            background: radial-gradient(circle at top, #eff6ff, #f9fafb 55%);
            color: var(--fg);
            line-height: 1.6;
        }

        a {
            color: var(--accent);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .page {
            max-width: 900px;
            margin: 0 auto;
            padding: 2.5rem 1.5rem 3rem;
        }

        header {
            text-align: center;
            margin-bottom: 2.5rem;
        }

        h1 {
            font-size: clamp(1.8rem, 2.6vw + 1rem, 2.4rem);
            margin: 0 0 0.75rem;
            letter-spacing: 0.02em;
        }

        .authors {
            color: var(--muted);
            font-size: 0.98rem;
        }

        .links-row {
            display: inline-flex;
            gap: 0.75rem;
            margin-top: 1.25rem;
            flex-wrap: wrap;
            justify-content: center;
        }

        .pill-link {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            padding: 0.45rem 0.9rem;
            border-radius: 999px;
            border: 1px solid var(--border);
            background: rgba(255, 255, 255, 0.85);
            font-size: 0.9rem;
            font-weight: 500;
            letter-spacing: 0.02em;
        }

        .pill-link.primary {
            border-color: var(--accent);
            background: var(--accent-soft);
        }

        main {
            background: var(--card-bg);
            border-radius: 1rem;
            border: 1px solid rgba(148, 163, 184, 0.2);
            box-shadow: 0 18px 45px rgba(15, 23, 42, 0.06),
            0 1px 0 rgba(255, 255, 255, 0.8) inset;
            padding: 1.5rem 1.5rem 1.75rem;
        }

        .video-wrapper {
            margin-bottom: 1.75rem;
        }

        .video-frame {
            position: relative;
            width: 100%;
            padding-top: 56.25%; /* 16:9 */
            border-radius: 0.75rem;
            overflow: hidden;
            background: #020617;
            border: 1px solid var(--border);
        }

        .video-frame iframe,
        .video-frame video {
            position: absolute;
            inset: 0;
            width: 100%;
            height: 100%;
            border: none;
        }

        section {
            margin-top: 1.25rem;
        }

        h2 {
            font-size: 2.0rem; /* 原来是 1.15rem，现在调大 */
            margin: 2rem 0 1.5rem; /* 原来是 0 0 0.5rem，现在增加上下边距 */
            letter-spacing: 0.08em;
            text-align: center; /* 新增：居中对齐 */
            font-weight: 600; /* 新增（可选）：加粗字体 */
        }

        p {
            margin: 0.25rem 0 0.75rem;
            font-size: 0.98rem;
        }

        .method-image {
            margin-top: 0.75rem;
            text-align: center;
        }

        .method-image img {
            max-width: 100%;
            height: auto;
            border-radius: 0.75rem;
            border: 1px solid var(--border);
        }

        .method-caption {
            margin-top: 0.3rem;
            font-size: 0.82rem;
            color: var(--muted);
        }

        @media (min-width: 768px) {
            main {
                padding: 1.8rem 2rem 2rem;
            }

            .video-wrapper {
                margin-bottom: 2rem;
            }
        }
    </style>
</head>
<body>
<div class="page">
    <header>
        <h1>Real-Time Dynamic Parameter Estimation for Legged Robot Sim-to-Real Adaptation</h1>
        <div class="authors">Anonymous Authors</div>

        <div class="links-row">
            <a
                    class="pill-link primary"
                    href="https://anonymous.4open.science/r/legged-sim2real-adaptation-20B4"
                    target="_blank"
                    rel="noopener noreferrer"
            >
                Code
            </a>
            <a
                    class="pill-link primary"
                    href="https://www.youtube.com/playlist?list=PLG-5CzJKb16SnrZxh_hAvW1XI_GIh05Qk"
                    target="_blank"
                    rel="noopener noreferrer"
            >
                Video
            </a>
        </div>
    </header>

    <main>
        <section id="abstract">
            <h2>Abstract</h2>
            <p style="text-align: justify;">
                The sim-to-real gap remains a critical barrier preventing learning-based policies from achieving high
                performance in real-world tasks. To address this challenge, we propose a real-time adaptation framework
                for legged robots. Our approach explicitly estimates dynamic parameters online using real-world data,
                with the policy conditioned on these estimated parameters to achieve optimal performance in current
                scenarios. Extensive experiments demonstrate that our method outperforms the baseline by 27% in velocity
                tracking, 84% in base orientation stability, and 39% in robustness on average. Moreover, the explicit
                estimates can be directly utilized for parameter-dependent downstream tasks such as payload mass
                identification, leash-guided quadruped control, and force-aware locomotion.
            </p>
        </section>

        <section id="method">
            <h2>Method</h2>
            <p style="text-align: justify;">
                Our method exploits real-world data to estimate dynamic parameters accurately in real-time and
                retrieves the parameter-conditioned policy from a parameter-augmented base policy, thereby take
                instance-specific information into consideration. In this work, we extend the notion of dynamic
                parameters beyond static physical quantities (e.g., inertial properties and actuator parameters) to
                include slowly time-varying external forces. Because forces like payload gravity and human-applied
                traction vary on timescales of seconds rather than exhibiting high-frequency stochastic behavior, they
                can be effectively estimated online as dynamic parameters rather than treated as unmodeled disturbances.
            </p>
            <div class="method-image">
                <img
                        src="overview.png"
                />
            </div>
            <p style="text-align: justify;">
                Since robot dynamic parameters remain relatively stable over short timescales, policies should condition
                on specific parameter values to maximize instance-specific rewards, rather than optimizing expected
                reward over the distribution of parameters. Specifically, the online adaptation module processes
                historical proprioceptive observations to produce estimates of dynamic parameters. To provide richer
                input to the policy network (actor), the online adaptation module simultaneously estimates the robot's
                base linear velocity and a latent variable. Estimation of dynamic parameters and linear velocities is
                learned via supervised training with simulation ground truth, while the latent variable is used to
                filter high-frequency environmental noise and enhance policy stability. The current proprioceptive
                observation, together with the output of the online adaptation module, serves as inputs to the policy
                network.
            </p>

        </section>

        <section id="force_est">
            <h2>Performance in Force Estimation</h2>
            <p style="text-align: justify;">
                We compared the external forces estimated by the online adaptation module with ground-truth measurements
                obtained from load cells and spring dynamometers in real-world experiments. The experimental data
                demonstrate that the online adaptation module achieves highly accurate force estimation, with relative
                errors below 10%.
            </p>
            <div class="video-wrapper">
                <div class="video-frame">
                    <iframe
                            src="https://www.youtube.com/embed/RRUDQszhlYE"
                            title="Payload Identification"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen
                    ></iframe>
                </div>
            </div>
            <div class="video-wrapper">
                <div class="video-frame">
                    <iframe
                            src="https://www.youtube.com/embed/m4iBWMmh5UU"
                            title="Lateral Force Identification"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen
                    ></iframe>
                </div>
            </div>
        </section>

        <section id="payload_loco">
            <h2>Performance in Locomotion</h2>
            <p style="text-align: justify;">
                We compared our method against a baseline using only domain randomization without adaptation mechanisms
                on payload locomotion tasks with an 8.5 kg payload (70% of the robot's weight). Our method outperforms
                the baseline in base orientation stability, base height control, and collision avoidance.
            </p>
            <div class="video-wrapper">
                <div class="video-frame">
                    <iframe
                            src="https://www.youtube.com/embed/yvWqQpbcAmU"
                            title="Payload Locomotion"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen
                    ></iframe>
                </div>
            </div>
        </section>

        <section id="leash_guide">
            <h2>Application: Leash-Guided Control</h2>
            <p style="text-align: justify;">
                Our method explicitly estimates robot dynamic parameters in real-time, which not only improves
                sim-to-real transfer but also enables parameter-dependent downstream tasks such as leash-guided control.
                In the following video, we set the velocity command to comply with the direction of the pulling force,
                exhibiting dog-walking-like behavior.
            </p>
            <div class="video-wrapper">
                <div class="video-frame">
                    <iframe
                            src="https://www.youtube.com/embed/JiJ_Vb7B2xk"
                            title="Leash-Guided Control"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen
                    ></iframe>
                </div>
            </div>
        </section>

    </main>
</div>
</body>
</html>